<!DOCTYPE html>
<html lang="en">
  <head><script type="text/javascript" src="/blog/lib/jquery/jquery.min.js"></script>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript" src="/blog/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/blog/lib/fancybox/jquery.fancybox.pack.js"></script>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="O ever youthful, O ever weeping."/><link rel="alternate" href="/blog/default" title="Onns Blog"><link rel="shortcut icon" type="image/x-icon" href="/blog/favicon.ico?v=2.11.0" />
<link rel="canonical" href="https://onns.xyz/page/12/"/>

<link rel="stylesheet" type="text/css" href="/blog/lib/fancybox/jquery.fancybox.css" /><script type="text/javascript">
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]  
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" async src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link rel="stylesheet" type="text/css" href="/blog/css/style.css?v=2.11.0" />

<script id="baidu_analytics">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?094f3776af9873aa4bf55d2700e2b1cc";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127068305-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127068305-1');
</script><script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script src="//cdn.jsdelivr.net/npm/leancloud-storage@4.6.1/dist/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "jIRe5LRqbWDB2dxmu7FH8c1S-gzGzoHsz",
      appKey: "pM10kNYtPMwvqYUCWfbUGBPJ",
      serverURLs: "https://lean.onns.xyz"
    });
  </script><script>
  window.config = {"leancloud":{"app_id":"jIRe5LRqbWDB2dxmu7FH8c1S-gzGzoHsz","app_key":"pM10kNYtPMwvqYUCWfbUGBPJ","server_urls":"https://lean.onns.xyz"},"toc":true,"fancybox":true,"pjax":true,"latex":true};
</script>

<script id="search">
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();

            var $input = document.getElementById(search_id);
			if (!$input) return;
            var $resultContent = document.getElementById(content_id);
            
            $input.addEventListener('input', function () {
                var str = '<section class=\"posts\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length <= 0) {
                    return;
                }
                // perform local searching
                datas.forEach(function (data) {
                    var isMatch = true;
                    var content_index = [];
                    if (!data.title || data.title.trim() === '') {
                        data.title = "Untitled";
                    }
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty contents
                    if (data_content !== '') {
                        keywords.forEach(function (keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);

                            if (index_title < 0 && index_content < 0) {
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                                // content_index.push({index_content:index_content, keyword_len:keyword_len});
                            }
                        });
                    } else {
                        isMatch = false;
                    }
                    // show search results
                    if (isMatch) {
                        str += `
<article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="`+ data_url +`">`+ data_title +`</a>
        </h1>
    </header>
    <div class="post-content">
        `;
                        var content = data.content.trim().replace(/<[^>]+>/g, "");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;

                            if (start < 0) {
                                start = 0;
                            }

                            if (start == 0) {
                                end = 100;
                            }

                            if (end > content.length) {
                                end = content.length;
                            }

                            var match_content = content.substring(start, end);

                            // highlight all keywords
                            keywords.forEach(function (keyword) {
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<code>" + keyword + "</code>");
                            });

                            str += "<p>" + match_content + "...</p>"
                        }
                        str += "</article>";
                    }
                });
                str += "</section>";
                $resultContent.innerHTML = str;
            });
        }
    });
}    
var search_path = "search.xml";
if (search_path.length == 0) {
search_path = "search.xml";
}
var path = "/blog/" + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script>
    <title>Onns Blog</title>
  <meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/blog/." class="logo">Onns Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/blog/home">
        <li class="mobile-menu-item">Home
          </li>
      </a><a href="/blog/archives">
        <li class="mobile-menu-item">Archives
          </li>
      </a><a href="/blog/tags">
        <li class="mobile-menu-item">Tags
          </li>
      </a><a href="/blog/categories">
        <li class="mobile-menu-item">Categories
          </li>
      </a><a href="/blog/about">
        <li class="mobile-menu-item">About
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/blog/." class="logo">Onns Blog</a>
</div>

<nav class="site-navbar"><div class="search-button">
        <a href="#" class="search-toggle" data-selector=".site-navbar"></a>
    </div>
    <div class="search-box">
        <input type="text" id="local-search-input" class="text search-input" placeholder="Type here to search..." />
    </div><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/blog/home">
            Home
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/archives">
            Archives
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/tags">
            Tags
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/categories">
            Categories
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/about">
            About
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            <div id="local-search-result"></div><section id="posts" class="posts"><article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/09/06/servlet-in-java-1/">从流中获取 properties</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-09-06 12:23:37
        </span><span class="post-category">
            <a href="/blog/categories/learn/">learn</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/09/06/servlet-in-java-1/"
             data-title="从流中获取 properties">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="idea-小技巧"><a class="header-anchor" href="#idea-小技巧">#</a>IDEA 小技巧</h2>
<ul>
<li><code>alt</code>按住移动鼠标可以多行编辑。</li>
<li><code>cmd + n</code>可以快速创建构造器（自行选择参数）或者重写继承方法。</li>
</ul>
          <div class="read-more">
            <a href="/blog/2020/09/06/servlet-in-java-1/" class="read-more-link">Read more..</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/09/05/gfnet-a-lightweight-group-frame-network-for-efficient-human-action-recognition/">GFNET A LIGHTWEIGHT GROUP FRAME NETWORK FOR EFFICIENT HUMAN ACTION RECOGNITION</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-09-05 12:23:47
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/09/05/gfnet-a-lightweight-group-frame-network-for-efficient-human-action-recognition/"
             data-title="GFNET A LIGHTWEIGHT GROUP FRAME NETWORK FOR EFFICIENT HUMAN ACTION RECOGNITION">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="gfnet-a-lightweight-group-frame-network-for-efficient-human-action-recognition"><a class="header-anchor" href="#gfnet-a-lightweight-group-frame-network-for-efficient-human-action-recognition">#</a>GFNET: A LIGHTWEIGHT GROUP FRAME NETWORK FOR EFFICIENT HUMAN ACTION RECOGNITION</h2>
<p>为了解决现有的行为识别方法<code>计算量大</code>、<code>参数多</code>的问题，作者提出了<code>GFNet</code>。</p>
<blockquote>
<p>To handle these issues, we propose a lightweight neural network called Group Frame Network (GFNet).</p>
</blockquote>
<p>GFNet 通过帧级分解，以极小的代价提取每一帧的特征。</p>
<blockquote>
<p>GFNet adds frame-level decomposition to extract features of each frame at a minuscule cost.</p>
</blockquote>
<p>设计了两个核心组件，能够仅从<code>RGB图像</code>中提取时空信息，而不需要借助<code>光流</code>或<code>multi-scale testing</code>等。</p>
<blockquote>
<p>There are two core components: <code>Group Temporal Module</code> (GTM) and <code>Group Spatial Module</code> (GSM). These two modules enable GFNet to obtain temporal-spatial information only from RGB images.</p>
</blockquote>
<p>为了证明模型的有效性，他们没有使用预训练策略。</p>
<blockquote>
<p>To verify the validity of the model, no pre-training strategy is used in our experiments.</p>
</blockquote>
<p>网络的输入是<code>一定数量</code>的<code>视频帧</code>，对视频进行分段采样得到结果。</p>
<blockquote>
<p>The entire video with a variable number of frames is provided as the input of the network. Through an average sampling strategy, the video is divided into N equal-length segments and only one frame is selected from each segment. Due to the repeatability of adjacent frames, this sampling strategy can reduce inter-frame redundancy while preserving long-temporal information.</p>
</blockquote>
<p>K 个层同时输入网络获取时间信息。</p>
<blockquote>
<p>The first part is a feature extraction layer consisting of K separated branches. The sampled frames are simultaneously fed into the network to maintain the temporal information among these frames.</p>
</blockquote>
<p>各自的分支独立计算获得空间信息。</p>
<blockquote>
<p>In the feature extraction layer, each frame is learned independently using a network branch to get its spatial features.</p>
</blockquote>
<p>没太理解。</p>
<blockquote>
<p>all the sampled frames are stacked by channel-wise convolution.<br>
It means that the input channel of GFNet is 3N when using RGB images as input.</p>
</blockquote>
<p>由于残差网络具有高度的泛化能力和性能，所以后续的块选择高度模块化残差单元。</p>
<blockquote>
<p>Owing to the impressive performance and strong generalization abil- ity of residual architecture, the block is based on the highly modularized residual unit.</p>
</blockquote>
<p>这句话没太理解。</p>
<blockquote>
<p>Considering the extraneous motion and identical texture features in sampled frames, GFNet decomposes frames and reduces the number of channels for each frame to lessen spatial redundancy. To be specific, the number of channels is equally divided among branches. It means that only a small number of channels are used per frame.</p>
</blockquote>
<h2 id="group-temporal-module"><a class="header-anchor" href="#group-temporal-module">#</a>Group Temporal Module</h2>
<p>因为每个分支都是单独计算的，所以势必会降低准确率（没有提取帧间的联系），所以提出了<code>GTM</code>模块。</p>
<blockquote>
<p>To leverage the inter-frame information effectively and better strengthen temporal relationships, GTM is proposed to efficiently overcome the side effects brought by the separated branch.</p>
</blockquote>
<blockquote>
<p>GTM consists of a translation layer and a 3D convolution layer.</p>
</blockquote>
<blockquote>
<p>The translation layer makes the replacement of the data dimension. It includes the channel merger and the channel separation, which achieves the conversion of the feature map from four-dimensional data to five-dimensional data.</p>
</blockquote>
<h2 id="group-spatial-module"><a class="header-anchor" href="#group-spatial-module">#</a>Group Spatial Module</h2>
<p>For the convolution layer of ResNet50, the computational cost is closely related to the number of channels. Motivated by this, a novel module called GSM is designed to significantly decrease the number of parameters and computational efforts.</p>
<p>GSM 也是通过只取纹理来最小化计算成本。</p>
<blockquote>
<p>Because of the similarity among frames, the texture information is repetitive. Meanwhile, irrelevant motion inside frames increases the intra-frame redundancy. Aiming at minimizing the interference of redundant information, GSM diminishes the number of channels to extract features per frame.</p>
</blockquote>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/09/02/maven-in-mac/">MacOS下配置maven</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-09-02 10:02:47
        </span><span class="post-category">
            <a href="/blog/categories/learn/">learn</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/09/02/maven-in-mac/"
             data-title="MacOS下配置maven">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><p>官方下载地址：<a href="http://maven.apache.org/download.cgi" target="_blank" rel="noopener">http://maven.apache.org/download.cgi</a></p>
<p>下载：<a href="https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz</a></p>
<p>解压之后，复制目录：<code>/Users/onns/Downloads/java/apache-maven-3.6.3</code></p>
<p>因为系统更新后，命令行从<code>bash</code>换成了<code>zsh</code>所以环境变量文件也改了：<code>.zshrc</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'export M2_HOME=/Users/onns/Downloads/java/apache-maven-3.6.3/bin'</span> &gt;&gt; .zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export MAVEN_HOME=/Users/onns/Downloads/java/apache-maven-3.6.3'</span> &gt;&gt; .zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=$MAVEN_HOME/bin:$PATH'</span> &gt;&gt; .zshrc</span><br></pre></td></tr></table></figure>
<p>让环境变量生效：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> .zshrc</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ mvn --version</span><br><span class="line">Apache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)</span><br><span class="line">Maven home: &#x2F;Users&#x2F;onns&#x2F;Downloads&#x2F;java&#x2F;apache-maven-3.6.3</span><br><span class="line">Java version: 13.0.2, vendor: Oracle Corporation, runtime: &#x2F;Library&#x2F;Java&#x2F;JavaVirtualMachines&#x2F;jdk-13.0.2.jdk&#x2F;Contents&#x2F;Home</span><br><span class="line">Default locale: en_CN, platform encoding: UTF-8</span><br><span class="line">OS name: &quot;mac os x&quot;, version: &quot;10.15.5&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;</span><br></pre></td></tr></table></figure>
<h2 id="修改镜像源"><a class="header-anchor" href="#修改镜像源">#</a>修改镜像源</h2>
<p>参照阿里云的使用指南：<a href="https://maven.aliyun.com/mvn/guide" target="_blank" rel="noopener">https://maven.aliyun.com/mvn/guide</a></p>
<p>打开<code>$MAVEN_HOME/conf/settings.xml</code></p>
<p>在<code>&lt;mirrors&gt;&lt;/mirrors&gt;</code>标签中添加<code>mirror</code>子节点：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>aliyunmaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>阿里云公共仓库<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://maven.aliyun.com/repository/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="配置本地仓库"><a class="header-anchor" href="#配置本地仓库">#</a>配置本地仓库</h2>
<p>打开<code>$MAVEN_HOME/conf/settings.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- localRepository</span></span><br><span class="line"><span class="comment"> | The path to the local repository maven will use to store artifacts.</span></span><br><span class="line"><span class="comment"> |</span></span><br><span class="line"><span class="comment"> | Default: $&#123;user.home&#125;/.m2/repository</span></span><br><span class="line"><span class="comment">&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>/Users/onns/Downloads/java/apache-maven-3.6.3/repo<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>完</p>
<h2 id="相关链接"><a class="header-anchor" href="#相关链接">#</a>相关链接</h2>
<ul>
<li><a href="https://www.bilibili.com/video/BV12J411M7Sj?p=5" target="_blank" rel="noopener">教程地址</a></li>
</ul>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/09/01/pan-towards-fast-action-recognition-via-learning-persistence-of-appearance/">PAN Towards Fast Action Recognition via Learning Persistence of Appearance</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-09-01 15:23:38
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/09/01/pan-towards-fast-action-recognition-via-learning-persistence-of-appearance/"
             data-title="PAN Towards Fast Action Recognition via Learning Persistence of Appearance">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="pan-towards-fast-action-recognition-via-learning-persistence-of-appearance"><a class="header-anchor" href="#pan-towards-fast-action-recognition-via-learning-persistence-of-appearance">#</a>PAN: Towards Fast Action Recognition via Learning Persistence of Appearance</h2>
<p>比光流网络快了1000倍</p>
<blockquote>
<p>Our PA is over 1000× faster (8196fps vs. 8fps) than conventional optical flow in terms of motion modeling speed</p>
</blockquote>
<p>运动边界的微小位移在动作识别中起重要作用的角色。</p>
<blockquote>
<p>According to the aforementioned anal- ysis, we can conclude that small displacements of motion boundaries play a vital role in action recognition.</p>
</blockquote>
<p>低层的<code>feature map</code>之间的差异能更多地关注边界的变化。</p>
<blockquote>
<p>the differences among low-level feature maps will pay more attention to the variations at boundaries.<br>
In summary, differences in low-level feature maps can reflect small displacements of motion boundaries due to convolutional operations.</p>
</blockquote>
<p>在<code>UCF101</code>上做实验表明在第一层效果最好。</p>
<blockquote>
<p>We define the basic conv-layer as eight 7×7 convolutions with stride=1 and padding=3, so that the spatial resolutions of the obtained feature maps are not reduced.</p>
</blockquote>
<p>两种编码策略：</p>
<p><strong>PA as motion modality</strong></p>
<p><strong>PA as attention</strong></p>
<p>第一种无论是从计算量上还是从准确率上都要更好。</p>
<p>可能原因是第二种融合方法导致图像的不平衡。</p>
<blockquote>
<p>However, for e2, attending appearance feature maps with PA will highlight the motion boundaries, leading to the imbalanced appearance responses both inside and at the boundaries of the moving objects.</p>
</blockquote>
<p><strong>Various-timescale Aggregation Pooling</strong></p>
<h2 id="安装测试"><a class="header-anchor" href="#安装测试">#</a>安装测试</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install torch torchvision</span><br><span class="line">pip install tensorboardX</span><br><span class="line">pip install tqdm</span><br><span class="line">pip install scikit-learn</span><br><span class="line">pip install lmdb</span><br></pre></td></tr></table></figure>
<h2 id="实验结果"><a class="header-anchor" href="#实验结果">#</a>实验结果</h2>
<h3 id="lite"><a class="header-anchor" href="#lite">#</a>Lite</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">somethingv2: 174 classes</span><br><span class="line">=&gt; <span class="built_in">shift</span>: True, shift_div: 8, shift_place: blockres</span><br><span class="line">=&gt; base model: resnet50</span><br><span class="line">Downloading: <span class="string">"https://download.pytorch.org/models/resnet50-19c8e357.pth"</span> to /home/xiangyi/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth</span><br><span class="line">100%|██████████████████████████████████████| 97.8M/97.8M [00:06&lt;00:00, 14.8MB/s]</span><br><span class="line">=&gt; Adding temporal <span class="built_in">shift</span>...</span><br><span class="line">=&gt; Using 3-level VAP</span><br><span class="line">=&gt; Converting the ImageNet model to a PAN_Lite init model</span><br><span class="line">=&gt; Done. PAN_lite model ready...</span><br><span class="line">video number:24777</span><br><span class="line">video 0 <span class="keyword">done</span>, total 0/24777, average 0.879 sec/video, moving Prec@1 65.625 Prec@5 87.500</span><br><span class="line">video 1280 <span class="keyword">done</span>, total 1280/24777, average 0.239 sec/video, moving Prec@1 60.491 Prec@5 85.640</span><br><span class="line">video 2560 <span class="keyword">done</span>, total 2560/24777, average 0.230 sec/video, moving Prec@1 60.518 Prec@5 85.671</span><br><span class="line">video 3840 <span class="keyword">done</span>, total 3840/24777, average 0.227 sec/video, moving Prec@1 60.015 Prec@5 85.374</span><br><span class="line">video 5120 <span class="keyword">done</span>, total 5120/24777, average 0.225 sec/video, moving Prec@1 60.031 Prec@5 85.475</span><br><span class="line">video 6400 <span class="keyword">done</span>, total 6400/24777, average 0.226 sec/video, moving Prec@1 59.855 Prec@5 85.334</span><br><span class="line">video 7680 <span class="keyword">done</span>, total 7680/24777, average 0.224 sec/video, moving Prec@1 59.775 Prec@5 85.292</span><br><span class="line">video 8960 <span class="keyword">done</span>, total 8960/24777, average 0.223 sec/video, moving Prec@1 59.519 Prec@5 85.284</span><br><span class="line">video 10240 <span class="keyword">done</span>, total 10240/24777, average 0.224 sec/video, moving Prec@1 59.530 Prec@5 85.423</span><br><span class="line">video 11520 <span class="keyword">done</span>, total 11520/24777, average 0.224 sec/video, moving Prec@1 59.686 Prec@5 85.497</span><br><span class="line">video 12800 <span class="keyword">done</span>, total 12800/24777, average 0.224 sec/video, moving Prec@1 59.678 Prec@5 85.487</span><br><span class="line">video 14080 <span class="keyword">done</span>, total 14080/24777, average 0.225 sec/video, moving Prec@1 59.637 Prec@5 85.464</span><br><span class="line">video 15360 <span class="keyword">done</span>, total 15360/24777, average 0.225 sec/video, moving Prec@1 59.349 Prec@5 85.315</span><br><span class="line">video 16640 <span class="keyword">done</span>, total 16640/24777, average 0.225 sec/video, moving Prec@1 59.327 Prec@5 85.327</span><br><span class="line">video 17920 <span class="keyword">done</span>, total 17920/24777, average 0.226 sec/video, moving Prec@1 59.058 Prec@5 85.204</span><br><span class="line">video 19200 <span class="keyword">done</span>, total 19200/24777, average 0.226 sec/video, moving Prec@1 59.121 Prec@5 85.206</span><br><span class="line">video 20480 <span class="keyword">done</span>, total 20480/24777, average 0.226 sec/video, moving Prec@1 59.200 Prec@5 85.295</span><br><span class="line">video 21760 <span class="keyword">done</span>, total 21760/24777, average 0.227 sec/video, moving Prec@1 59.283 Prec@5 85.337</span><br><span class="line">video 23040 <span class="keyword">done</span>, total 23040/24777, average 0.227 sec/video, moving Prec@1 59.254 Prec@5 85.422</span><br><span class="line">video 24320 <span class="keyword">done</span>, total 24320/24777, average 0.227 sec/video, moving Prec@1 59.277 Prec@5 85.421</span><br><span class="line">[0.84482759 0.38815789 0.51633987 0.58252427 0.58974359 0.54385965</span><br><span class="line"> 0.76738609 0.63636364 0.67716535 0.60264901 0.53932584 0.68613139</span><br><span class="line"> 0.26923077 0.425      0.7122807  0.51914894 0.42639594 0.38157895</span><br><span class="line"> 0.46025105 0.57345972 0.51574803 0.62280702 0.55232558 0.56382979</span><br><span class="line"> 0.56818182 0.52631579 0.6        0.48514851 0.71818182 0.77394636</span><br><span class="line"> 0.78378378 0.77477477 0.82954545 0.11650485 0.36144578 0.203125</span><br><span class="line"> 0.84331797 0.82129278 0.22222222 0.79411765 0.71584699 0.73214286</span><br><span class="line"> 0.59624413 0.62057878 0.72972973 0.51253482 0.5873494  0.40703518</span><br><span class="line"> 0.42857143 0.80430108 0.7257384  0.06666667 0.40625    0.68571429</span><br><span class="line"> 0.25       0.42       0.4109589  0.60377358 0.17647059 0.81654676</span><br><span class="line"> 0.92       0.21568627 0.73417722 0.30841121 0.21621622 0.53301887</span><br><span class="line"> 0.30188679 0.40298507 0.6754386  0.43       0.64285714 0.47826087</span><br><span class="line"> 0.54411765 0.61538462 0.66981132 0.36842105 0.5        0.30769231</span><br><span class="line"> 0.2962963  0.77586207 0.296875   0.168      0.36170213 0.44680851</span><br><span class="line"> 0.64       0.44444444 0.85882353 0.792      0.25       0.19277108</span><br><span class="line"> 0.56521739 0.85       0.57894737 0.764      0.76694915 0.13888889</span><br><span class="line"> 0.14705882 0.2892562  0.51020408 0.67765568 0.46792453 0.62637363</span><br><span class="line"> 0.29310345 0.8125     0.7480315  0.73333333 0.52054795 0.66502463</span><br><span class="line"> 0.39189189 0.48       0.6056338  0.05555556 0.49640288 0.27777778</span><br><span class="line"> 0.69097222 0.54347826 0.25925926 0.77777778 0.40677966 0.64356436</span><br><span class="line"> 0.80314961 0.80681818 0.34975369 0.69230769 0.36538462 0.63761468</span><br><span class="line"> 0.55339806 0.42608696 0.1302682  0.70955882 0.32142857 0.35616438</span><br><span class="line"> 0.44827586 0.24561404 0.79619565 0.62269939 0.23529412 0.45</span><br><span class="line"> 0.24770642 0.72727273 0.6627907  0.359375   0.59375    0.63311688</span><br><span class="line"> 0.56050955 0.44680851 0.74166667 0.0859375  0.55230126 0.90754717</span><br><span class="line"> 0.76902174 0.33152174 0.3877551  0.75229358 0.51181102 0.29268293</span><br><span class="line"> 0.5        0.58695652 0.55045872 0.34545455 0.41284404 0.46052632</span><br><span class="line"> 0.43925234 0.45       0.84398977 0.88709677 0.96428571 0.94444444</span><br><span class="line"> 0.81666667 0.70666667 0.45098039 0.72115385 0.74418605 0.65693431]</span><br><span class="line">upper bound: 0.548518228331384</span><br><span class="line">-----Evaluation is finished------</span><br><span class="line">Class Accuracy 53.84%</span><br><span class="line">Overall Prec@1 59.26% Prec@5 85.45%</span><br><span class="line">/home/xiangyi/miniconda3/envs/pan/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (<span class="built_in">which</span> is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to <span class="keyword">do</span> this, you must specify <span class="string">'dtype=object'</span> when creating the ndarray</span><br><span class="line">  <span class="built_in">return</span> array(a, dtype, copy=False, order=order, subok=True)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line">$ python test_models.py somethingv2 --VAP --batch_size=16 -j=4 --test_crops=1 --test_segments=8 --weights=pretrained/PAN_Lite_somethingv2_resnet50_shift8_blockres_avg_segment8_e80.pth.tar</span><br><span class="line">somethingv2: 174 classes</span><br><span class="line">=&gt; <span class="built_in">shift</span>: True, shift_div: 8, shift_place: blockres</span><br><span class="line">=&gt; base model: resnet50</span><br><span class="line">=&gt; Adding temporal <span class="built_in">shift</span>...</span><br><span class="line">=&gt; Using 3-level VAP</span><br><span class="line">=&gt; Converting the ImageNet model to a PAN_Lite init model</span><br><span class="line">=&gt; Done. PAN_lite model ready...</span><br><span class="line">video number:24777</span><br><span class="line">video 0 <span class="keyword">done</span>, total 0/24777, average 4.263 sec/video, moving Prec@1 56.250 Prec@5 81.250</span><br><span class="line">video 320 <span class="keyword">done</span>, total 320/24777, average 0.481 sec/video, moving Prec@1 65.476 Prec@5 86.310</span><br><span class="line">video 640 <span class="keyword">done</span>, total 640/24777, average 0.399 sec/video, moving Prec@1 60.976 Prec@5 85.213</span><br><span class="line">video 960 <span class="keyword">done</span>, total 960/24777, average 0.452 sec/video, moving Prec@1 60.246 Prec@5 85.348</span><br><span class="line">video 1280 <span class="keyword">done</span>, total 1280/24777, average 0.424 sec/video, moving Prec@1 60.880 Prec@5 85.802</span><br><span class="line">video 1600 <span class="keyword">done</span>, total 1600/24777, average 0.400 sec/video, moving Prec@1 60.458 Prec@5 85.334</span><br><span class="line">video 1920 <span class="keyword">done</span>, total 1920/24777, average 0.397 sec/video, moving Prec@1 60.227 Prec@5 85.537</span><br><span class="line">video 2240 <span class="keyword">done</span>, total 2240/24777, average 0.398 sec/video, moving Prec@1 60.151 Prec@5 85.594</span><br><span class="line">video 2560 <span class="keyword">done</span>, total 2560/24777, average 0.390 sec/video, moving Prec@1 60.404 Prec@5 85.637</span><br><span class="line">video 2880 <span class="keyword">done</span>, total 2880/24777, average 0.388 sec/video, moving Prec@1 60.290 Prec@5 85.463</span><br><span class="line">video 3200 <span class="keyword">done</span>, total 3200/24777, average 0.386 sec/video, moving Prec@1 60.261 Prec@5 85.572</span><br><span class="line">video 3520 <span class="keyword">done</span>, total 3520/24777, average 0.380 sec/video, moving Prec@1 60.436 Prec@5 85.605</span><br><span class="line">video 3840 <span class="keyword">done</span>, total 3840/24777, average 0.372 sec/video, moving Prec@1 60.062 Prec@5 85.425</span><br><span class="line">video 4160 <span class="keyword">done</span>, total 4160/24777, average 0.368 sec/video, moving Prec@1 59.962 Prec@5 85.321</span><br><span class="line">video 4480 <span class="keyword">done</span>, total 4480/24777, average 0.367 sec/video, moving Prec@1 59.831 Prec@5 85.343</span><br><span class="line">video 4800 <span class="keyword">done</span>, total 4800/24777, average 0.365 sec/video, moving Prec@1 59.884 Prec@5 85.507</span><br><span class="line">video 5120 <span class="keyword">done</span>, total 5120/24777, average 0.362 sec/video, moving Prec@1 60.008 Prec@5 85.533</span><br><span class="line">video 5440 <span class="keyword">done</span>, total 5440/24777, average 0.358 sec/video, moving Prec@1 60.392 Prec@5 85.521</span><br><span class="line">video 5760 <span class="keyword">done</span>, total 5760/24777, average 0.355 sec/video, moving Prec@1 60.336 Prec@5 85.457</span><br><span class="line">video 6080 <span class="keyword">done</span>, total 6080/24777, average 0.352 sec/video, moving Prec@1 60.285 Prec@5 85.400</span><br><span class="line">video 6400 <span class="keyword">done</span>, total 6400/24777, average 0.351 sec/video, moving Prec@1 59.804 Prec@5 85.318</span><br><span class="line">video 6720 <span class="keyword">done</span>, total 6720/24777, average 0.348 sec/video, moving Prec@1 59.650 Prec@5 85.125</span><br><span class="line">video 7040 <span class="keyword">done</span>, total 7040/24777, average 0.347 sec/video, moving Prec@1 59.736 Prec@5 85.204</span><br><span class="line">video 7360 <span class="keyword">done</span>, total 7360/24777, average 0.344 sec/video, moving Prec@1 59.585 Prec@5 85.182</span><br><span class="line">video 7680 <span class="keyword">done</span>, total 7680/24777, average 0.342 sec/video, moving Prec@1 59.771 Prec@5 85.265</span><br><span class="line">video 8000 <span class="keyword">done</span>, total 8000/24777, average 0.341 sec/video, moving Prec@1 59.681 Prec@5 85.292</span><br><span class="line">video 8320 <span class="keyword">done</span>, total 8320/24777, average 0.339 sec/video, moving Prec@1 59.633 Prec@5 85.281</span><br><span class="line">video 8640 <span class="keyword">done</span>, total 8640/24777, average 0.337 sec/video, moving Prec@1 59.635 Prec@5 85.386</span><br><span class="line">video 8960 <span class="keyword">done</span>, total 8960/24777, average 0.336 sec/video, moving Prec@1 59.548 Prec@5 85.316</span><br><span class="line">video 9280 <span class="keyword">done</span>, total 9280/24777, average 0.334 sec/video, moving Prec@1 59.477 Prec@5 85.273</span><br><span class="line">video 9600 <span class="keyword">done</span>, total 9600/24777, average 0.333 sec/video, moving Prec@1 59.536 Prec@5 85.358</span><br><span class="line">video 9920 <span class="keyword">done</span>, total 9920/24777, average 0.331 sec/video, moving Prec@1 59.652 Prec@5 85.397</span><br><span class="line">video 10240 <span class="keyword">done</span>, total 10240/24777, average 0.331 sec/video, moving Prec@1 59.565 Prec@5 85.413</span><br><span class="line">video 10560 <span class="keyword">done</span>, total 10560/24777, average 0.330 sec/video, moving Prec@1 59.503 Prec@5 85.354</span><br><span class="line">video 10880 <span class="keyword">done</span>, total 10880/24777, average 0.329 sec/video, moving Prec@1 59.554 Prec@5 85.380</span><br><span class="line">video 11200 <span class="keyword">done</span>, total 11200/24777, average 0.330 sec/video, moving Prec@1 59.576 Prec@5 85.396</span><br><span class="line">video 11520 <span class="keyword">done</span>, total 11520/24777, average 0.329 sec/video, moving Prec@1 59.639 Prec@5 85.480</span><br><span class="line">video 11840 <span class="keyword">done</span>, total 11840/24777, average 0.327 sec/video, moving Prec@1 59.691 Prec@5 85.417</span><br><span class="line">video 12160 <span class="keyword">done</span>, total 12160/24777, average 0.326 sec/video, moving Prec@1 59.675 Prec@5 85.422</span><br><span class="line">video 12480 <span class="keyword">done</span>, total 12480/24777, average 0.325 sec/video, moving Prec@1 59.675 Prec@5 85.451</span><br><span class="line">video 12800 <span class="keyword">done</span>, total 12800/24777, average 0.325 sec/video, moving Prec@1 59.691 Prec@5 85.471</span><br><span class="line">video 13120 <span class="keyword">done</span>, total 13120/24777, average 0.324 sec/video, moving Prec@1 59.645 Prec@5 85.490</span><br><span class="line">video 13440 <span class="keyword">done</span>, total 13440/24777, average 0.323 sec/video, moving Prec@1 59.617 Prec@5 85.486</span><br><span class="line">video 13760 <span class="keyword">done</span>, total 13760/24777, average 0.322 sec/video, moving Prec@1 59.640 Prec@5 85.475</span><br><span class="line">video 14080 <span class="keyword">done</span>, total 14080/24777, average 0.321 sec/video, moving Prec@1 59.641 Prec@5 85.464</span><br><span class="line">video 14400 <span class="keyword">done</span>, total 14400/24777, average 0.322 sec/video, moving Prec@1 59.600 Prec@5 85.502</span><br><span class="line">video 14720 <span class="keyword">done</span>, total 14720/24777, average 0.323 sec/video, moving Prec@1 59.521 Prec@5 85.437</span><br><span class="line">video 15040 <span class="keyword">done</span>, total 15040/24777, average 0.323 sec/video, moving Prec@1 59.358 Prec@5 85.355</span><br><span class="line">video 15360 <span class="keyword">done</span>, total 15360/24777, average 0.323 sec/video, moving Prec@1 59.365 Prec@5 85.341</span><br><span class="line">video 15680 <span class="keyword">done</span>, total 15680/24777, average 0.322 sec/video, moving Prec@1 59.353 Prec@5 85.302</span><br><span class="line">video 16000 <span class="keyword">done</span>, total 16000/24777, average 0.321 sec/video, moving Prec@1 59.328 Prec@5 85.340</span><br><span class="line">video 16320 <span class="keyword">done</span>, total 16320/24777, average 0.322 sec/video, moving Prec@1 59.341 Prec@5 85.327</span><br><span class="line">video 16640 <span class="keyword">done</span>, total 16640/24777, average 0.320 sec/video, moving Prec@1 59.312 Prec@5 85.315</span><br><span class="line">video 16960 <span class="keyword">done</span>, total 16960/24777, average 0.320 sec/video, moving Prec@1 59.295 Prec@5 85.315</span><br><span class="line">video 17280 <span class="keyword">done</span>, total 17280/24777, average 0.320 sec/video, moving Prec@1 59.256 Prec@5 85.291</span><br><span class="line">video 17600 <span class="keyword">done</span>, total 17600/24777, average 0.321 sec/video, moving Prec@1 59.191 Prec@5 85.280</span><br><span class="line">video 17920 <span class="keyword">done</span>, total 17920/24777, average 0.321 sec/video, moving Prec@1 59.066 Prec@5 85.220</span><br><span class="line">video 18240 <span class="keyword">done</span>, total 18240/24777, average 0.321 sec/video, moving Prec@1 59.109 Prec@5 85.232</span><br><span class="line">video 18560 <span class="keyword">done</span>, total 18560/24777, average 0.321 sec/video, moving Prec@1 59.189 Prec@5 85.255</span><br><span class="line">video 18880 <span class="keyword">done</span>, total 18880/24777, average 0.320 sec/video, moving Prec@1 59.113 Prec@5 85.198</span><br><span class="line">video 19200 <span class="keyword">done</span>, total 19200/24777, average 0.319 sec/video, moving Prec@1 59.128 Prec@5 85.205</span><br><span class="line">video 19520 <span class="keyword">done</span>, total 19520/24777, average 0.319 sec/video, moving Prec@1 59.142 Prec@5 85.227</span><br><span class="line">video 19840 <span class="keyword">done</span>, total 19840/24777, average 0.319 sec/video, moving Prec@1 59.136 Prec@5 85.244</span><br><span class="line">video 20160 <span class="keyword">done</span>, total 20160/24777, average 0.320 sec/video, moving Prec@1 59.199 Prec@5 85.255</span><br><span class="line">video 20480 <span class="keyword">done</span>, total 20480/24777, average 0.320 sec/video, moving Prec@1 59.202 Prec@5 85.290</span><br><span class="line">video 20800 <span class="keyword">done</span>, total 20800/24777, average 0.319 sec/video, moving Prec@1 59.204 Prec@5 85.295</span><br><span class="line">video 21120 <span class="keyword">done</span>, total 21120/24777, average 0.319 sec/video, moving Prec@1 59.226 Prec@5 85.328</span><br><span class="line">video 21440 <span class="keyword">done</span>, total 21440/24777, average 0.318 sec/video, moving Prec@1 59.270 Prec@5 85.314</span><br><span class="line">video 21760 <span class="keyword">done</span>, total 21760/24777, average 0.318 sec/video, moving Prec@1 59.285 Prec@5 85.342</span><br><span class="line">video 22080 <span class="keyword">done</span>, total 22080/24777, average 0.318 sec/video, moving Prec@1 59.314 Prec@5 85.355</span><br><span class="line">video 22400 <span class="keyword">done</span>, total 22400/24777, average 0.318 sec/video, moving Prec@1 59.284 Prec@5 85.377</span><br><span class="line">video 22720 <span class="keyword">done</span>, total 22720/24777, average 0.318 sec/video, moving Prec@1 59.236 Prec@5 85.340</span><br><span class="line">video 23040 <span class="keyword">done</span>, total 23040/24777, average 0.317 sec/video, moving Prec@1 59.256 Prec@5 85.414</span><br><span class="line">video 23360 <span class="keyword">done</span>, total 23360/24777, average 0.317 sec/video, moving Prec@1 59.274 Prec@5 85.417</span><br><span class="line">video 23680 <span class="keyword">done</span>, total 23680/24777, average 0.317 sec/video, moving Prec@1 59.246 Prec@5 85.403</span><br><span class="line">video 24000 <span class="keyword">done</span>, total 24000/24777, average 0.318 sec/video, moving Prec@1 59.231 Prec@5 85.389</span><br><span class="line">video 24320 <span class="keyword">done</span>, total 24320/24777, average 0.317 sec/video, moving Prec@1 59.291 Prec@5 85.413</span><br><span class="line">video 24640 <span class="keyword">done</span>, total 24640/24777, average 0.317 sec/video, moving Prec@1 59.259 Prec@5 85.436</span><br><span class="line">[0.84482759 0.38815789 0.51633987 0.58252427 0.58974359 0.54385965</span><br><span class="line"> 0.76738609 0.63636364 0.67716535 0.60264901 0.53932584 0.68613139</span><br><span class="line"> 0.26923077 0.425      0.7122807  0.51914894 0.42639594 0.38157895</span><br><span class="line"> 0.46025105 0.57345972 0.51574803 0.62280702 0.55232558 0.56382979</span><br><span class="line"> 0.56818182 0.52631579 0.6        0.48514851 0.71818182 0.77394636</span><br><span class="line"> 0.78378378 0.77477477 0.82954545 0.11650485 0.36144578 0.203125</span><br><span class="line"> 0.84331797 0.82129278 0.22222222 0.79411765 0.71584699 0.73214286</span><br><span class="line"> 0.59624413 0.62057878 0.72972973 0.51253482 0.5873494  0.40703518</span><br><span class="line"> 0.42857143 0.80430108 0.7257384  0.06666667 0.40625    0.68571429</span><br><span class="line"> 0.25       0.42       0.4109589  0.60377358 0.17647059 0.81654676</span><br><span class="line"> 0.92       0.21568627 0.73417722 0.30841121 0.21621622 0.53301887</span><br><span class="line"> 0.30188679 0.40298507 0.6754386  0.43       0.64285714 0.47826087</span><br><span class="line"> 0.54411765 0.61538462 0.66981132 0.36842105 0.5        0.30769231</span><br><span class="line"> 0.2962963  0.77586207 0.296875   0.168      0.36170213 0.44680851</span><br><span class="line"> 0.64       0.44444444 0.85882353 0.792      0.25       0.19277108</span><br><span class="line"> 0.56521739 0.85       0.57894737 0.764      0.76694915 0.13888889</span><br><span class="line"> 0.14705882 0.2892562  0.51020408 0.67765568 0.46792453 0.62637363</span><br><span class="line"> 0.29310345 0.8125     0.7480315  0.73333333 0.52054795 0.66502463</span><br><span class="line"> 0.39189189 0.48       0.6056338  0.05555556 0.49640288 0.27777778</span><br><span class="line"> 0.69097222 0.54347826 0.25925926 0.77777778 0.40677966 0.64356436</span><br><span class="line"> 0.80314961 0.80681818 0.34975369 0.69230769 0.36538462 0.63761468</span><br><span class="line"> 0.55339806 0.42608696 0.1302682  0.70955882 0.32142857 0.35616438</span><br><span class="line"> 0.44827586 0.24561404 0.79619565 0.62269939 0.23529412 0.45</span><br><span class="line"> 0.24770642 0.72727273 0.6627907  0.359375   0.59375    0.63311688</span><br><span class="line"> 0.56050955 0.44680851 0.74166667 0.0859375  0.55230126 0.90754717</span><br><span class="line"> 0.76902174 0.33152174 0.3877551  0.75229358 0.51181102 0.29268293</span><br><span class="line"> 0.5        0.58695652 0.55045872 0.34545455 0.41284404 0.46052632</span><br><span class="line"> 0.43925234 0.45       0.84398977 0.88709677 0.96428571 0.94444444</span><br><span class="line"> 0.81666667 0.70666667 0.45098039 0.72115385 0.74418605 0.65693431]</span><br><span class="line">upper bound: 0.548518228331384</span><br><span class="line">-----Evaluation is finished------</span><br><span class="line">Class Accuracy 53.84%</span><br><span class="line">Overall Prec@1 59.26% Prec@5 85.45%</span><br><span class="line">E:\Program Files\Anaconda3\envs\tsm\lib\site-packages\numpy\core\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (<span class="built_in">which</span> is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to <span class="keyword">do</span> this, you must specify <span class="string">'dtype=object'</span> when creating the ndarray</span><br><span class="line">  <span class="built_in">return</span> array(a, dtype, copy=False, order=order, subok=True)</span><br></pre></td></tr></table></figure>
<h2 id="相关链接"><a class="header-anchor" href="#相关链接">#</a>相关链接</h2>
<ul>
<li><a href="https://arxiv.org/pdf/2008.03462v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/2008.03462v1.pdf</a></li>
<li><a href="https://github.com/zhang-can/PAN-PyTorch" target="_blank" rel="noopener">https://github.com/zhang-can/PAN-PyTorch</a></li>
</ul>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/08/30/tsm-temporal-shift-module-for-efficient-video-understanding/">TSM Temporal Shift Module for Efficient Video Understanding</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-30 16:14:30
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/08/30/tsm-temporal-shift-module-for-efficient-video-understanding/"
             data-title="TSM Temporal Shift Module for Efficient Video Understanding">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h1 id="tsm-temporal-shift-module-for-efficient-video-understanding"><a class="header-anchor" href="#tsm-temporal-shift-module-for-efficient-video-understanding">#</a>TSM: Temporal Shift Module for Efficient Video Understanding</h1>
<center>
<p><img src="//onns.xyz/blog/image/20200910-1.png" alt="核心思想"></p>
</center>
<p>文章实现了在 2D 模型上达到 3D 模型的精度，极大的降低了计算。其核心思想是通过一种<code>shift</code>操作，将时间纬度上的不同帧之间的通道进行偏移，以达到共享时间特征的目的。</p>
<p>然而并不是所有的<code>shift</code>操作都可以达到效果的，虽然<code>shift</code>操作不需要额外的运算但是仍然需要数据的移动，太多的移动会带来延迟。</p>
<p>除此之外，<code>shift</code>是增加时间特征的提取，太多的<code>shift</code>操作也会导致空间特征的提取受到影响。</p>
<center>
<p><img src="//onns.xyz/blog/image/20200910-2.png" alt="作者思路"></p>
</center>
<p>故文章中所提出的是一种改进的<code>shift</code>策略：并不是<code>shift</code>所有的<code>channels</code>，而是只选择性的<code>shift</code>其中的一部分，该策略能够有效的减少数据移动所带来的时间复杂度。</p>
<p>另外<code>TSM</code>并不是直接被插入到从前往后的干道中的，而是以旁路的形式进行，因此在获得了时序信息的同时不会对二维卷积的空间信息进行损害。</p>
<p>同时作者对于一些实时的在线检测提出了相应的模型策略，不同于将第一层下移第二层上移这种：</p>
<center>
<p><img src="//onns.xyz/blog/image/20200910-3.png" alt="在线模型"></p>
</center>
<p>可以有相应的借鉴思路，并且这篇也是上一篇的基准之一。</p>
<h2 id="实验结果"><a class="header-anchor" href="#实验结果">#</a>实验结果</h2>
<center>
<p><img src="//onns.xyz/blog/image/20200910-7.png" alt="过程"></p>
</center>
<center>
<p><img src="//onns.xyz/blog/image/20200910-8.png" alt="结果"></p>
</center>
<h2 id="相关链接"><a class="header-anchor" href="#相关链接">#</a>相关链接</h2>
<ul>
<li><a href="https://github.com/mit-han-lab/temporal-shift-module" target="_blank" rel="noopener">https://github.com/mit-han-lab/temporal-shift-module</a></li>
<li><a href="https://blog.csdn.net/justsolow/article/details/105127296" target="_blank" rel="noopener">《TSM: Temporal Shift Module for Efficient Video Understanding》学习小记</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/66251207" target="_blank" rel="noopener">Temporal Shift Module</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/64525610" target="_blank" rel="noopener">TSM：Temporal Shift Module for 视频理解</a></li>
<li><a href="https://blog.csdn.net/Amazingren/article/details/100715768" target="_blank" rel="noopener">【视频理解论文】——TSM：Temporal Shift Module for Efficient Video Understanding</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/64525610" target="_blank" rel="noopener">TSM：Temporal Shift Module for 视频理解</a></li>
<li><a href="https://blog.csdn.net/strawqqhat/article/details/105292687" target="_blank" rel="noopener">Temporal Shift Module for Efficient Video Understanding</a></li>
</ul>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/08/30/gate-shift-networks-for-video-action-recognition/">Gate-Shift Networks for Video Action Recognition</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-30 08:44:25
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/08/30/gate-shift-networks-for-video-action-recognition/"
             data-title="Gate-Shift Networks for Video Action Recognition">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="gate-shift-networks-for-video-action-recognition"><a class="header-anchor" href="#gate-shift-networks-for-video-action-recognition">#</a>Gate-Shift Networks for Video Action Recognition</h2>
<p>用于行为识别的<code>Gate-Shift</code>网络</p>
<p>在实践中，由于涉及大量的参数和计算，在缺乏足够大的数据集进行大规模训练的情况下，<code>C3D</code>可能表现不佳。</p>
<center>
<p><img src="//onns.xyz/blog/image/20200910-5.png" alt="GSM"></p>
</center>
<p>文章提出了一种<code>Gate-Shift Module(GSM)</code>，将<code>2D-CNN</code>转换为高效的时空特征抽取器。</p>
<p>通过<code>GSM</code>插件，一个<code>2D-CNN</code>可以适应性地学习时间路由特性并将它们结合起来，并且几乎没有额外的附加参数和计算开销。</p>
<center>
<p><img src="//onns.xyz/blog/image/20200910-4.png" alt="思路对比"></p>
</center>
<p>传统的方法演变：<code>C3D</code> -&gt; <code>2D spatial + 1D temporal</code> -&gt; <code>CSN</code> -&gt; <code>GST</code>（与分离信道组上的二维和三维卷积并行空间和时空交互建模） -&gt; <code>TSM</code>（时域卷积可以被限制为硬编码的时移，使一些信道在时间上向前或向后移动）</p>
<p>所有这些现有的方法都学习具有硬连线连接和跨网络传播模式的结构化内核。<br>
在网络中的任何一点上都没有数据依赖的决策来选择地通过不同的分支来路由特性，分组和随机的模式是在设计之初就固定的，并且学习如何随机是具有组合复杂性的。</p>
<center>
<p><img src="//onns.xyz/blog/image/20200910-6.png" alt="实验"></p>
</center>
<blockquote>
<p>From the experiments we conclude that adding GSM to the branch with the least number of convolution layers performs the best.</p>
</blockquote>
<p><code>GSM</code>通过一种门移模块，来让网络自己学习<code>TSM</code>中的<code>shift</code>操作，并通过实验证明在卷积层最少的分支上添加<code>GSM</code>模块表现最好。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/08/30/weekly-report-20200830/">周报-20200830</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-30 07:50:29
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/08/30/weekly-report-20200830/"
             data-title="周报-20200830">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><center>
<table>
<thead>
<tr>
<th style="text-align:center">2020-08-30</th>
<th style="text-align:center">周报#03</th>
<th style="text-align:center">刘潘</th>
</tr>
</thead>
<tbody></tbody>
</table>
</center>
          <div class="read-more">
            <a href="/blog/2020/08/30/weekly-report-20200830/" class="read-more-link">Read more..</a>
          </div>
        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/08/30/weekly-report-template/">Markdown格式的周报模板</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-30 07:32:57
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/08/30/weekly-report-template/"
             data-title="Markdown格式的周报模板">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">center</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line">| date | report#ID | name |</span><br><span class="line">| :--: | :-------: | :--: |</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">center</span>&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="section">## I. Task achieved last week</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="section">## II. Reports</span></span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="section">## III. Plan for this week</span></span><br><span class="line"></span><br><span class="line">---</span><br></pre></td></tr></table></figure>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/08/29/a-behavioral-recognition-algorithm-based-on-2d-spatiotemporal-information-extraction/">一种基于 2D 时空信息提取的行为识别算法</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-29 14:24:12
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/08/29/a-behavioral-recognition-algorithm-based-on-2d-spatiotemporal-information-extraction/"
             data-title="一种基于 2D 时空信息提取的行为识别算法">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="一种基于-2d-时空信息提取的行为识别算法"><a class="header-anchor" href="#一种基于-2d-时空信息提取的行为识别算法">#</a>一种基于 2D 时空信息提取的行为识别算法</h2>
<p>在<code>UCF101</code>数据集上准确率<code>94.46%</code>。</p>
<p>采用<code>DenseNet</code>做为网络的架构。</p>
<p>从一个视频片段提取出 <code>16</code> 帧的 <code>64 × 64 × 3</code> 的有时序顺序的图像，组织成 <code>4 × 4</code> 的图像。</p>
<center>
<p><img src="//onns.xyz/blog/image/20200829-1.png" alt="图像翻转设计"></p>
</center>
<center>
<p><img src="//onns.xyz/blog/image/20200829-2.png" alt="实验结果"></p>
</center>
<p>文章没有具体说明执行速度，但是我觉得应该比基于视频的快很多，也相对来讲更有实践性。</p>

        </div></article>
      <article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="/blog/2020/08/28/disentangling-and-unifying-graph-convolutionsfor-skeleton-based-action-recognition/">Disentangling and Unifying Graph Convolutionsfor Skeleton-Based Action Recognition</a>
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-08-28 15:04:15
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/08/28/disentangling-and-unifying-graph-convolutionsfor-skeleton-based-action-recognition/"
             data-title="Disentangling and Unifying Graph Convolutionsfor Skeleton-Based Action Recognition">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-content"><h2 id="disentangling-and-unifying-graph-convolutionsfor-skeleton-based-action-recognition"><a class="header-anchor" href="#disentangling-and-unifying-graph-convolutionsfor-skeleton-based-action-recognition">#</a>Disentangling and Unifying Graph Convolutionsfor Skeleton-Based Action Recognition</h2>
<p>基于骨架的动作识别的分离统一图卷积</p>
<p>在多尺度算子下无偏的远程联合关系建模<br>
在信息流中无障碍的跨时空捕获复杂的时空依赖性</p>
<h2 id="introduction"><a class="header-anchor" href="#introduction">#</a>Introduction</h2>
<p>首先介绍了一下基于人体骨架的行为识别的高效性和广阔前景。</p>
<p>对于骨架图的鲁棒动作识别，一个理想的算法应该不仅仅局限于局部关节连通性，提取多尺度结构特征和长距离依赖关系，因为结构上分离的关节也具有很强的相关性。</p>
<p>现有的方法是通过图卷积的骨架邻接矩阵的高阶多项式，邻接多项式通过使远邻可到达而增加了图卷积的感受野。</p>
<p>但因此就会出现<code>biased weighting problem</code>，即<code>偏加权问题</code>。更高的多项式阶在从远端关节获取信息方面仅具有一点点的效果，因为聚集的特征将由来自局部身体部位的关节控制。这是限制现有多尺度聚合器可扩展性的一个关键缺点。</p>
<p>鲁棒算法的另一个可取特征是能够利用复杂的跨时空联合关系进行动作识别。然而，为了达到这一目的，大多数现有的方法都是使用交错的空间独立（spatial-only）和时间独立（temporal-only）模型，类似于分解的三维卷积。一种典型的方法是首先使用图卷积提取每个时间片的空间关系，然后使用循环的或一维卷积层来模拟时间动态。这种<code>因式分解</code>允许高效的远程建模，它支持跨时空的直接信息流，但是它无法捕获复杂的区域时空联合依赖关系。例如，“站起来”的动作常常同时发生上下身体跨越时空的运动，上半身的运动（前倾）与下半身的运动（站起来）有着强烈的关联。<code>因式分解</code>建模可能无法有效地捕捉到做出预测的有力线索。</p>
<ol>
<li>我们提出了一个分离的多尺度聚合方案，该方案消除了来自不同邻域的节点特征之间的冗余依赖关系，从而使强大的多尺度聚合器能够有效地捕获人类骨骼上的图形范围的关节关系。</li>
<li>我们提出了一个<code>G3D</code>操作单元。它促进了信息在时空中的直接流动，从而有效地进行特征学习。</li>
<li>将分离的聚集方案与 G3D 集成，提供了一个强大的特征抽取器（MS-G3D），具有跨空间和时间维度的多尺度感受野。时空特性的直接多尺度聚合进一步提高了模型性能。</li>
</ol>
<h2 id="相关链接"><a class="header-anchor" href="#相关链接">#</a>相关链接</h2>
<ul>
<li><a href="https://www.pianshen.com/article/75261564402/" target="_blank" rel="noopener">别人的笔记 1</a></li>
<li><a href="https://blog.csdn.net/qq_36852840/article/details/106374430" target="_blank" rel="noopener">别人的笔记 2</a></li>
<li><a href="https://blog.csdn.net/m0_37852937/article/details/106565861" target="_blank" rel="noopener">别人的笔记 3</a></li>
<li><a href="https://github.com/kenziyuliu/ms-g3d" target="_blank" rel="noopener">github 源码</a></li>
</ul>

        </div></article>
      <nav class="pagination"><a class="prev" href="/blog/page/11/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text">Prev</span>
      </a>
    <a class="next" href="/blog/page/13/">
        <span class="next-text">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></section></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:onns@onns.xyz" class="iconfont icon-email" title="email"></a>
        <a href="https://facebook.com/onnsxyz" target="_blank" rel="noopener" class="iconfont icon-facebook" title="facebook"></a>
        <a href="https://github.com/onns" target="_blank" rel="noopener" class="iconfont icon-github" title="github"></a>
        <a href="https://www.douban.com/people/onnsxyz/" target="_blank" rel="noopener" class="iconfont icon-douban" title="douban"></a>
        <a href="https://instagram.com/onnsxyz" target="_blank" rel="noopener" class="iconfont icon-instagram" title="instagram"></a>
        <a href="/blog/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even" target="_blank" rel="noopener">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2021<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Onns</span>
    <span class="licence"> <a href="http://www.beian.miit.gov.cn" target="_blank" rel="noopener">闽ICP备15022938号-2</a> </span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/blog/js/src/even.js?v=2.11.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
