<!DOCTYPE html>
<html lang="en">
  <head><script type="text/javascript" src="/blog/lib/jquery/jquery.min.js"></script>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript" src="/blog/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/blog/lib/fancybox/jquery.fancybox.pack.js"></script>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="MotionSqueeze Neural Motion FeatureLearning for Video Understanding"/><meta name="keywords" content="行为识别, action recognition, ECCV, msnet, ECCV 2020, Onns Blog" /><link rel="alternate" href="/blog/default" title="Onns Blog"><link rel="shortcut icon" type="image/x-icon" href="/blog/favicon.ico?v=2.11.0" />
<link rel="canonical" href="https://onns.xyz/2020/10/20/motionsqueeze-neural-motion-feature-learning-for-video-understanding/"/>

<link rel="stylesheet" type="text/css" href="/blog/lib/fancybox/jquery.fancybox.css" /><script type="text/javascript">
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]  
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" async src="//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link rel="stylesheet" type="text/css" href="/blog/css/style.css?v=2.11.0" />

<script id="baidu_analytics">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?094f3776af9873aa4bf55d2700e2b1cc";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127068305-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127068305-1');
</script><script src="//onns.xyz/js/av-min.js"></script>
  <script id="leancloud">
    AV.init({
      appId: "jIRe5LRqbWDB2dxmu7FH8c1S-gzGzoHsz",
      appKey: "pM10kNYtPMwvqYUCWfbUGBPJ",
      serverURLs: "https://jire5lrq.lc-cn-n1-shared.com"
    });
  </script><script>
  window.config = {"leancloud":{"app_id":"jIRe5LRqbWDB2dxmu7FH8c1S-gzGzoHsz","app_key":"pM10kNYtPMwvqYUCWfbUGBPJ","server_urls":"https://jire5lrq.lc-cn-n1-shared.com"},"toc":true,"fancybox":true,"pjax":true,"latex":true};
</script>

<script id="search">
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();

            var $input = document.getElementById(search_id);
			if (!$input) return;
            var $resultContent = document.getElementById(content_id);
            
            $input.addEventListener('input', function () {
                var str = '<section class=\"posts\">';
                var rawValue = this.value.trim().toLowerCase();
                if (rawValue.length <= 0) {
                    return;
                }
                var keywords = [];
                for (const matchKey of rawValue.matchAll(/"([^"]*)"/g)) {
                  keywords.push(matchKey[1]);
                  rawValue = rawValue.replace(matchKey[0], "");
                }
                keywords = keywords.concat(rawValue.split(/[\s\-]+/));
                keywords = keywords.filter(function(el) {
                    return el.trim().length > 0;
                });
                if (keywords.length <= 0) {
                    return;
                }
                $resultContent.innerHTML = "";
                
                // perform local searching
                datas.forEach(function (data) {
                    var isMatch = true;
                    var content_index = [];
                    if (!data.title || data.title.trim() === '') {
                        data.title = "Untitled";
                    }
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty contents
                    if (data_content !== '') {
                        keywords.forEach(function (keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);

                            if (index_title < 0 && index_content < 0) {
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                                // content_index.push({index_content:index_content, keyword_len:keyword_len});
                            }
                        });
                    } else {
                        isMatch = false;
                    }
                    // show search results
                    if (isMatch) {
                        str += `
<article class="post">
    <header class="post-header">
      <h1 class="post-title"><a class="post-link" href="`+ data_url +`">`+ data_title +`</a>
        </h1>
    </header>
    <div class="post-content">
        `;
                        var content = data.content.trim().replace(/<[^>]+>/g, "");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;

                            if (start < 0) {
                                start = 0;
                            }

                            if (start == 0) {
                                end = 100;
                            }

                            if (end > content.length) {
                                end = content.length;
                            }

                            var match_content = content.substring(start, end);

                            // highlight all keywords
                            keywords.forEach(function (keyword) {
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<code>" + keyword + "</code>");
                            });

                            str += "<p>" + match_content + "...</p>"
                        }
                        str += "</article>";
                    }
                });
                str += "</section>";
                $resultContent.innerHTML = str;
            });
        }
    });
}    
var search_path = "search.xml";
if (search_path.length == 0) {
search_path = "search.xml";
}
var path = "/blog/" + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script>
    <title>MotionSqueeze Neural Motion FeatureLearning for Video Understanding - Onns Blog</title>
  <meta name="generator" content="Hexo 4.2.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="mobile-header-logo">
    <a href="/blog/." class="logo">Onns Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/blog/home">
        <li class="mobile-menu-item">Home
          </li>
      </a><a href="/blog/archives">
        <li class="mobile-menu-item">Archives
          </li>
      </a><a href="/blog/tags">
        <li class="mobile-menu-item">Tags
          </li>
      </a><a href="/blog/categories">
        <li class="mobile-menu-item">Categories
          </li>
      </a><a href="/blog/about">
        <li class="mobile-menu-item">About
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/blog/." class="logo">Onns Blog</a>
</div>

<nav class="site-navbar"><div class="search-button">
        <a href="#" class="search-toggle" data-selector=".site-navbar"></a>
    </div>
    <div class="search-box">
        <input type="text" id="local-search-input" class="text search-input" placeholder="Type here to search..." />
    </div><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/blog/home">
            Home
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/archives">
            Archives
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/tags">
            Tags
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/categories">
            Categories
            </a>
        </li>
      <li class="menu-item">
          <a class="menu-item-link" href="/blog/about">
            About
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            <div id="local-search-result"></div><article class="post">
    <header class="post-header">
      <h1 class="post-title">MotionSqueeze Neural Motion FeatureLearning for Video Understanding
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-10-20 13:51:34
        </span><span class="post-category">
            <a href="/blog/categories/study/">study</a>
            </span>
        <span class="post-visits"
             data-url="/blog/2020/10/20/motionsqueeze-neural-motion-feature-learning-for-video-understanding/"
             data-title="MotionSqueeze Neural Motion FeatureLearning for Video Understanding">
          Visits 0
        </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#motionsqueeze-neural-motion-feature-learning-for-video-understanding"><span class="toc-text">MotionSqueeze: Neural Motion Feature Learning for Video Understanding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#相关工作"><span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ms模块"><span class="toc-text">MS模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#相关性计算"><span class="toc-text">相关性计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#位移估计"><span class="toc-text">位移估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征变换"><span class="toc-text">特征变换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#详细代码"><span class="toc-text">详细代码</span></a></li></ol>
    </div>
  </div><div class="post-content"><h2 id="motionsqueeze-neural-motion-feature-learning-for-video-understanding"><a class="header-anchor" href="#motionsqueeze-neural-motion-feature-learning-for-video-understanding">#</a>MotionSqueeze: Neural Motion Feature Learning for Video Understanding</h2>
<p>主要的创新点是<code>MS module</code>，它把这个结构插入到了<code>ResNet</code>的网络中间，具体来说在<code>layer2</code>之后，<code>layer3</code>之前。</p>
<center>
<!-- //onns.xyz/blog/image -->
<p><img src="//onns.xyz/blog/image/20201022-1.png" alt="结构图"></p>
</center>
<p>逻辑上如下图所示，道理上说得很清楚，首先进行关联性计算，就是为了判断当前的点可能会位移到什么位置，即什么位置的点最有可能是由当前的点位移过去的。</p>
<p>然后通过估计上的点，计算偏移。</p>
<p>最后计算特征转换。（这个其实我没太理解）</p>
<center>
<!-- //onns.xyz/blog/image -->
<p><img src="//onns.xyz/blog/image/20201022-2.png" alt="结构图"></p>
</center>
<a id="more"></a>
<h2 id="相关工作"><a class="header-anchor" href="#相关工作">#</a>相关工作</h2>
<p>对于一个视频来说，动作是最显著的特征，动作模型提取得好，识别的准确率就会提高。</p>
<p>卷积在捕获平移等变化的模型上具备有效性，但是对相对运动的物体上建模就很难让人感到满意。</p>
<blockquote>
<p>convolution is effective in capturing translation-equivariant patterns but not in modeling relative movement of objects</p>
</blockquote>
<p>论文的主要工作放在如何学习动作特征上。</p>
<blockquote>
<p>we focus on efficient learning of motion features.</p>
</blockquote>
<p>一些现有的研究方向进展：</p>
<ol>
<li>有一些在推理部分不需要光流输入，但是训练仍然需要的。</li>
<li>通过计算特征的时空梯度来表征动作特征。</li>
<li>提出了一种卷积模块，通过在外观特征之间进行空间移动和减法运算来提取运动特征。</li>
<li>计算卷积神经网络中间层的特征层光流，虽然效果很好，但是需要很高的计算量，因为在网络中间层进行操作。</li>
</ol>
<p>光流估计方法：</p>
<ol>
<li>对特征图构建张量，并对张量进行回归。</li>
<li>通过堆叠的特征层来进行粗略的光流估计。</li>
</ol>
<p>不过这些方法都需要光流图做<code>ground-truth</code>。</p>
<p>最近的一些相关工作：</p>
<ol>
<li>利用连续帧的特征图之间的相关信息来代替光学图像。不过这个完整模型的大小与双流网络相当。</li>
<li>提出<code>correspondences proposal</code>模块来学习视频间的联系。</li>
</ol>
<h2 id="ms模块"><a class="header-anchor" href="#ms模块">#</a>MS模块</h2>
<p>主要分为三个步骤<code>相关性计算</code>（correlation computation）、<code>位移估计</code>（displacement estimation）和<code>特征变换</code>（feature transformation）。</p>
<h3 id="相关性计算"><a class="header-anchor" href="#相关性计算">#</a>相关性计算</h3>
<p>定义给定的某一个特征层的输入特征图$\mathbf{F}^{(t)}$和$\mathbf{F}^{(t+1)}$，$\mathbf{F}$的大小为：</p>
<p>$$<br>
\mathbf{F} \in \mathbb{R}^{C \times H \times W}<br>
$$</p>
<p>对于某一个位置$\mathbf{x}$和位移$\mathbf{p}$的相关性可以通过下列公式得到：</p>

$$
s(\mathbf{x},\mathbf{p},t)=\mathbf{F}^{(t)}_{\mathbf{x}} \cdot \mathbf{F}^{(t+1)}_{\mathbf{x}+\mathbf{p}}
$$

<p>$\cdot$代表<code>点积</code>。</p>
<p>为了保证计算效率，同时也可以从经验中得到其实一个位置的运动相对不会很大（鉴于数据集是25帧-56帧不等，其实也还是蛮大的）<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>，$\mathbf{p}$有一个范围$\mathbf{p}\in[-k,k]^2$。</p>
<p>最终相关性结果为：</p>
<p>$$<br>
\mathbf{S}^{(t)} \in \mathbb{R}^{H \times W \times P^2}, P=2k+1<br>
$$</p>
<p>这个计算量与$P^2$个$1 \times 1$的卷积核计算量相当，整个视频的FLOPs为$T H W C P^2$。</p>
<p>在计算相关性之前，先在前面进行一次卷积操作，目的是为了对这些特征通道进行加权，进而来学习相关的视觉联系。</p>
<blockquote>
<p>We apply a convolution layer before computing correlations, which learns to weight informative feature channels for learning visual correspondences.</p>
</blockquote>
<center>
<!-- //onns.xyz/blog/image -->
<p><img src="//onns.xyz/blog/image/20201102-1.png" alt="MS结构图"></p>
</center>
<h3 id="位移估计"><a class="header-anchor" href="#位移估计">#</a>位移估计</h3>
<p>在前面，我们已经得到了某个点，与这个点在下一帧图像中周围点的相关性张量，然后就可以找出这里面相关性最大的点做位移估计。</p>
<p>最简单且最有效地方法当然是直接用$\mathrm{argmax}_{\mathbf{p}}s(\mathbf{x},\mathbf{p},t)$来计算，但是这个方法是<code>不可微的</code>，所以用一个替代方法：<code>soft-argmax</code>，定义如下：</p>
<p>$$<br>
d(\mathbf{x},t) = \sum_{\mathbf{p}} \frac{\exp(s(\mathbf{x},\mathbf{p},t))}{\sum_{\mathbf{p}’}{\exp(s(\mathbf{x},\mathbf{p}’,t))}} \mathbf{p}.<br>
$$</p>
<p>但是这个方法会对周围的噪点比较敏感，因为他受所有的点的值影响，解决方法是：<code>kernel-soft-argmax</code>，思路是对非中心点进行抑制，所以得到的结果大部分会来自中心点，及周围相关的点：</p>
<p>$$<br>
d(\mathbf{x},t) = \sum_{\mathbf{p}} \frac{\exp(g(\mathbf{x},\mathbf{p},t)s(\mathbf{x},\mathbf{p},t) / \tau )}{\sum_{\mathbf{p}’}{\exp( g(\mathbf{x},\mathbf{p}’,t) s(\mathbf{x},\mathbf{p}’,t) / \tau )}}  \mathbf{p},<br>
$$</p>
<p>$$<br>
g(\mathbf{x},\mathbf{p},t) = \frac{1}{\sqrt{2\pi}\sigma}\exp(\frac{\mathbf{p}-\mathrm{argmax}_{\mathbf{p}}s(\mathbf{x},\mathbf{p},t)}{\sigma^{2}})<br>
$$</p>
<p>根据经验，令$\sigma=5$。$\tau$是一个温度因子，用来调节<code>softmax</code>的分布，随着$\tau$的下降，<code>softmax</code>表现为<code>argmax</code>，令$\tau=0.01$。</p>
<p>除此之外，使用相关置信度图作为辅助运动信息，求解方法是对每个位置点$\mathbf{x}$进行最大池化：</p>
<p>$$<br>
s^{*}(\mathbf{x},t) =\max_{\mathbf{p}}s(\mathbf{x},\mathbf{p},t)<br>
$$</p>
<p>$$<br>
\mathbf{S}^* \in \mathbb{R}^{H \times W \times 1}<br>
$$</p>
<p>论文里说位移估计最后出来有两个通道，但是我目前还不知道为什么是双通道，待到看代码应该可以知道。</p>
<p>然后把两通道和上面的单通道合并，得到位移估计张量：</p>
<p>$$<br>
\mathbf{D}^{(t)} \in \mathbb{R}^{H \times W \times 3}<br>
$$</p>
<center>
<!-- //onns.xyz/blog/image -->
<p><img src="//onns.xyz/blog/image/20201102-1.png" alt="MS结构图"></p>
</center>
<h3 id="特征变换"><a class="header-anchor" href="#特征变换">#</a>特征变换</h3>
<p>用四层卷积卷，<code>depth-wise separable convolution</code>，因为上述特征都是通过两帧相减得到的，所以最后会少一个特征，论文直接令$\mathbf{M}^{(T)}=\mathbf{M}^{(T-1)}$，$\mathbf{M}^{(T)}$是上一步的$\mathbf{D}^{(T)}$卷积得到的。</p>
<p>经过卷积操作，也恢复成了原来的尺寸：</p>
<p>$$<br>
\mathbf{D}^{(t)} \in \mathbb{R}^{H \times W \times C}<br>
$$</p>
<center>
<!-- //onns.xyz/blog/image -->
<p><img src="//onns.xyz/blog/image/20201102-1.png" alt="MS结构图"></p>
</center>
<p>最终的结果会加回到原来的特征图上，论文通过做实验发现这样效果最好：</p>
<p>$$<br>
\mathbf{F}’^{(t)} =\mathbf{F}^{(t)} + \mathbf{M}^{(t)}<br>
$$</p>
<center>
<!-- //onns.xyz/blog/image -->
<p><img src="//onns.xyz/blog/image/20201102-2.png" alt="网络图"></p>
</center>
<h2 id="详细代码"><a class="header-anchor" href="#详细代码">#</a>详细代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = self.layer1(x)                             </span><br><span class="line">x = self.layer2(x)          </span><br><span class="line"></span><br><span class="line"><span class="comment"># Flow </span></span><br><span class="line">flow_1, match_v = self.flow_computation(x, temperature=temperature)</span><br><span class="line">x = self.flow_refinement(flow_1, x, match_v)</span><br><span class="line"><span class="comment"># EndFlow </span></span><br><span class="line"></span><br><span class="line">x = self.layer3(x)                           </span><br><span class="line">x = self.layer4(x)</span><br></pre></td></tr></table></figure>
<p>首先是代码入口，代码就是在<code>ResNet</code>的层之间添加的，具体的是在<code>layer2</code>和<code>layer3</code>之间。一共有两个方法，一共是上面说的<code>MS</code>的计算，即<code>flow_computation</code>，这里出来的结果是上面说的$\mathbf{D}^{(t)}$，上面说过$\mathbf{D}^{(t)}$有三个通道，<code>flow_1</code>是前两个<code>光流通道</code>，<code>match_v</code>是第三个的辅助运动信息，即$\mathbf{S}^*$。第二个是<code>MS</code>的几个卷积层+最终的融合，就是从$\mathbf{D}^{(t)}$到$\mathbf{M}^{(t)}$再到$\mathbf{F}'^{(t)}$的过程，即<code>flow_refinement</code>。</p>
<p>然后看一下<code>flow_computation</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flow_computation</span><span class="params">(self, x, pos=<span class="number">2</span>, temperature=<span class="number">100</span>)</span>:</span></span><br><span class="line">	</span><br><span class="line">	x = self.chnl_reduction(x)</span><br><span class="line">	<span class="comment"># chnl_reduction 源码如下，主要做的操作是降低通道数</span></span><br><span class="line">	<span class="comment"># self.chnl_reduction = nn.Sequential(</span></span><br><span class="line">	<span class="comment">#     nn.Conv2d(128*block.expansion, 64, kernel_size=1, stride=1, padding=0, bias=False),</span></span><br><span class="line">	<span class="comment">#     nn.BatchNorm2d(64),</span></span><br><span class="line">	<span class="comment">#     nn.ReLU(inplace=True)</span></span><br><span class="line">	<span class="comment"># )</span></span><br><span class="line">	</span><br><span class="line">	size = x.size()               </span><br><span class="line">	x = x.view((<span class="number">-1</span>, self.num_segments) + size[<span class="number">1</span>:])        <span class="comment"># N T C H W</span></span><br><span class="line">	x = x.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>).contiguous() <span class="comment"># B C T H W   </span></span><br><span class="line">					</span><br><span class="line">	<span class="comment"># match to flow            </span></span><br><span class="line">	k = <span class="number">1</span>            </span><br><span class="line">	temperature = temperature                    </span><br><span class="line">	b,c,t,h,w = x.size()            </span><br><span class="line">	t = t<span class="number">-1</span>         </span><br><span class="line"></span><br><span class="line">	x_pre = x[:,:,:<span class="number">-1</span>].permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>).contiguous().view(<span class="number">-1</span>,c,h,w)</span><br><span class="line">	x_post = x[:,:,<span class="number">1</span>:].permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>).contiguous().view(<span class="number">-1</span>,c,h,w)</span><br><span class="line">		</span><br><span class="line">	match = self.matching_layer(x_pre, x_post)    <span class="comment"># (B*T-1*group, H*W, H*W)          </span></span><br><span class="line">	u, v, confidence = self.match_to_flow_soft(match, k, h, w, temperature)</span><br><span class="line">	flow = tr.cat([u,v], dim=<span class="number">1</span>).view(<span class="number">-1</span>, <span class="number">2</span>*k, h, w)  <span class="comment">#  (b, 2, h, w)            </span></span><br><span class="line">			</span><br><span class="line">	<span class="comment"># backward flow</span></span><br><span class="line"><span class="comment">#             match2 = self.matching_layer(x_post, x_pre)</span></span><br><span class="line"><span class="comment">#             u_2, v_2, confidence_2 = self.match_to_flow_soft(match2, k, h, w,temperature)       </span></span><br><span class="line"><span class="comment">#             flow_2 = tr.cat([u_2,v_2],dim=1).view(-1,2, h, w)   </span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> flow, confidence</span><br></pre></td></tr></table></figure>
<p>首先进行了降低通道数的操作，然后对于不同 $t$ 时刻的特征图，进行<code>matching_layer</code>操作，得到<code>match</code>张量，对应论文中的$\mathbf{S}^{(t)}$，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">feature1 = self.L2normalize(feature1)</span><br><span class="line">feature2 = self.L2normalize(feature2)</span><br><span class="line">b, c, h1, w1 = feature1.size()</span><br><span class="line">b, c, h2, w2 = feature2.size()</span><br><span class="line">corr = self.correlation_sampler(feature1, feature2)</span><br><span class="line">corr = corr.view(b, self.patch * self.patch, h1* w1) <span class="comment"># Channel : target // Spatial grid : source</span></span><br><span class="line">corr = self.relu(corr)</span><br><span class="line"><span class="keyword">return</span> corr</span><br></pre></td></tr></table></figure>
<p>直接写了一个<code>forward</code>方法，<code>correlation_sampler</code>调用的是一个第三方的库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.correlation_sampler = SpatialCorrelationSampler(ks, patch, stride, pad, patch_dilation)</span><br></pre></td></tr></table></figure>
<p>总得来说就是求相关性的。</p>
<p>然后是<code>match_to_flow_soft</code>方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">match_to_flow_soft</span><span class="params">(self, match, k, h,w, temperature=<span class="number">1</span>, mode=<span class="string">'softmax'</span>)</span>:</span>        </span><br><span class="line">	b, c , s = match.size()     </span><br><span class="line">	idx = tr.arange(h*w, dtype=tr.float32).to(<span class="string">'cuda'</span>)</span><br><span class="line">	idx_x = idx % w</span><br><span class="line">	idx_x = idx_x.repeat(b,k,<span class="number">1</span>).to(<span class="string">'cuda'</span>)</span><br><span class="line">	idx_y = tr.floor(idx / w)   </span><br><span class="line">	idx_y = idx_y.repeat(b,k,<span class="number">1</span>).to(<span class="string">'cuda'</span>)</span><br><span class="line"></span><br><span class="line">	soft_idx_x = idx_x[:,:<span class="number">1</span>]</span><br><span class="line">	soft_idx_y = idx_y[:,:<span class="number">1</span>]</span><br><span class="line">	displacement = (self.patch<span class="number">-1</span>)/<span class="number">2</span></span><br><span class="line">	</span><br><span class="line">	topk_value, topk_idx = tr.topk(match, k, dim=<span class="number">1</span>)    <span class="comment"># (B*T-1, k, H*W)</span></span><br><span class="line">	topk_value = topk_value.view(<span class="number">-1</span>,k,h,w)</span><br><span class="line">	</span><br><span class="line">	match = self.apply_gaussian_kernel(match, h, w, self.patch, sigma=<span class="number">5</span>)</span><br><span class="line">	match = match*temperature</span><br><span class="line">	match_pre = self.soft_argmax(match)</span><br><span class="line">	smax = match_pre           </span><br><span class="line">	smax = smax.view(b,self.patch,self.patch,h,w)</span><br><span class="line">	x_kernel = tr.arange(-displacement*self.patch_dilation, displacement*self.patch_dilation+<span class="number">1</span>, step=self.patch_dilation, dtype=tr.float).to(<span class="string">'cuda'</span>)</span><br><span class="line">	y_kernel = tr.arange(-displacement*self.patch_dilation, displacement*self.patch_dilation+<span class="number">1</span>, step=self.patch_dilation, dtype=tr.float).to(<span class="string">'cuda'</span>)</span><br><span class="line">	x_mult = x_kernel.expand(b,self.patch).view(b,self.patch,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">	y_mult = y_kernel.expand(b,self.patch).view(b,self.patch,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">		</span><br><span class="line">	smax_x = smax.sum(dim=<span class="number">1</span>, keepdim=<span class="literal">False</span>) <span class="comment">#(b,w=k,h,w)</span></span><br><span class="line">	smax_y = smax.sum(dim=<span class="number">2</span>, keepdim=<span class="literal">False</span>) <span class="comment">#(b,h=k,h,w)</span></span><br><span class="line">	flow_x = (smax_x*x_mult).sum(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).view(<span class="number">-1</span>,<span class="number">1</span>,h*w) <span class="comment"># (b,1,h,w)</span></span><br><span class="line">	flow_y = (smax_y*y_mult).sum(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).view(<span class="number">-1</span>,<span class="number">1</span>,h*w) <span class="comment"># (b,1,h,w)    </span></span><br><span class="line"></span><br><span class="line">	flow_x = (flow_x / (self.patch_dilation * displacement))</span><br><span class="line">	flow_y = (flow_y / (self.patch_dilation * displacement))</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">return</span> flow_x, flow_y, topk_value</span><br></pre></td></tr></table></figure>
<p>这里就可以解释上面的疑问了，为什么匹配出来的通道数是<code>2</code>，就是和光流一样的原因，一个是<code>x</code>方向上的，一个是<code>y</code>方向上的。</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>这第二句话是我自己加的，论文里只是为了保证计算效率。 <a href="#fnref1" class="footnote-backref">↩︎</a></p>
</li>
</ol>
</section>

      </div>
      
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/blog/tags/%E8%A1%8C%E4%B8%BA%E8%AF%86%E5%88%AB/">行为识别</a>
            <a href="/blog/tags/action-recognition/">action recognition</a>
            <a href="/blog/tags/ECCV/">ECCV</a>
            <a href="/blog/tags/msnet/">msnet</a>
            <a href="/blog/tags/ECCV-2020/">ECCV 2020</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/blog/2020/10/22/weekly-report-20201022/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">周报-20201022</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    <a class="next" href="/blog/2020/10/20/temporal-relational-reasoning-in-videos/">
        <span class="next-text nav-default">Temporal Relational Reasoning in Videos</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"><div id="gitalk-container"></div>
    </div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:onns@onns.xyz" class="iconfont icon-email" title="email"></a>
        <a href="https://facebook.com/onnsxyz" target="_blank" rel="noopener" class="iconfont icon-facebook" title="facebook"></a>
        <a href="https://github.com/onns" target="_blank" rel="noopener" class="iconfont icon-github" title="github"></a>
        <a href="https://www.douban.com/people/onnsxyz/" target="_blank" rel="noopener" class="iconfont icon-douban" title="douban"></a>
        <a href="https://instagram.com/onnsxyz" target="_blank" rel="noopener" class="iconfont icon-instagram" title="instagram"></a>
        <a href="/blog/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even" target="_blank" rel="noopener">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2022<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">Onns</span>
    <span class="licence"> <a href="http://www.beian.miit.gov.cn" target="_blank" rel="noopener">闽ICP备15022938号-2</a> </span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css"/>


<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '7ebadcd52312c2b34f81',
    clientSecret: '052f4cb2121b344c1acd459e277d1bcdc53d1bce',
    repo: 'onns.xyz',
    owner: 'onns',
    admin: ['onns'],
    id: md5(location.pathname),
    
      language: window.navigator.language || window.navigator.userLanguage,
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script><script type="text/javascript" src="/blog/js/src/even.js?v=2.11.0"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
